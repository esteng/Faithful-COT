'''Derive the answer from the completions generated by model.
This is useful when you need to run the prediction script on a server, where it may be non-trivial to install certain solvers (e.g. SoufflÃ©).
In this case, you can simply run `predict.py` with the `--completion_only` flag, which will generate the completions only but not derive the answer.
Then, on your local machine with the necessary solvers installed, you can run this script to derive the answer from the completions.
'''
import os
cwd = os.getcwd()
if cwd.endswith("source/predict"):
	os.chdir("../..")  # change the working directory to the root directory
import sys
sys.path.append("source")
from configuration.configuration import Config
import argparse
from model.codex import Model
from dataset.utils import load_data
import jsonlines

if __name__ == "__main__":

	Parser = argparse.ArgumentParser()
	Parser.add_argument("--dataset_name", help="The name of the dataset.", choices=["GSM8K", "ASDiv", "MultiArith", "SVAMP", "AQUA", "date", "StrategyQA", "sports", "saycan", "CLUTRR"])
	Parser.add_argument("--split", help="The split of the dataset.", choices=["train", "dev", "test"])
	Parser.add_argument("--model_name", help="The name of the model (should have a corresponding config file under `configuration/config_files/dataset_name` called `{model_name}.json`.)")
	Parser.add_argument("--debug", help="If true, only run on the first 10 examples.", action="store_true")

	args = Parser.parse_args()
	model_name = args.model_name
	dataset_name = args.dataset_name
	split = args.split
	debug = args.debug

	config_frn = f"source/configuration/config_files/{dataset_name}/{model_name}.json"
	config = Config.from_json_file(config_frn)
	config.split = split
	config.dataset_name = dataset_name

	# load the dataset
	dataset_frn = f"data/{dataset_name}/{split}.jsonl"
	dataset = load_data(dataset_frn)

	# load the model
	model = Model(config)

	# predict
	output_dir = f"output_dir/{dataset_name}/{split}/{model_name}"
	completion_frn = f"{output_dir}/predictions_completion_only{'_debug' if debug else ''}.jsonl"
	completions = load_data(completion_frn)

	output_fwn = f"{output_dir}/predictions{'_debug' if debug else ''}.jsonl"

	# load existing predictions if any
	existing_preds = {}
	line_id = 0
	if os.path.isfile(output_fwn):
		with open(output_fwn, "r") as fr:
			reader = jsonlines.Reader(fr)
			for line_id, line in enumerate(reader):
				example_id = line["id"]
	if line_id > 0:
		start_id = line_id+1
	else:
		start_id = 0

	print(f"Staring from the {start_id}th example...")

	with open(output_fwn, 'w') as fw:
		writer = jsonlines.Writer(fw, flush=True)

		for i, (example, prediction) in enumerate(dataset, completions):
			if debug and i >= 10:
				break
			if i < start_id:
				continue

			if "completions" in prediction:
				completion = [prediction["completion"]]
			elif "completions" in prediction:
				completions = prediction["completions"]
			else:
				raise ValueError(f"Neither 'completion' nor 'completions' found in example {i}.")

			question = example["question"]
			answer, final_completion = model.derive_answer_from_completions(question, completions)
			prediction["answer"] = answer
			writer.write(prediction)

	print(f"Finished predicting on {i+1} examples. Output written to {output_fwn}.")
